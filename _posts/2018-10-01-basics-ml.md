---
title: 'Introduction to Machine Learning'
date: 2018-10-01
permalink: /posts/2018/11/basics-ml/
tags:
  - Machine Learning
  - Basics
---

Roughly speaking, learning is the process of converting experience into expertise or knowledge.

## 1. Why Machine Learning and what is it?

### 1.1. Why Machine Learning?

We need Machine Learning because there are tasks that change with time (adaptivity) that are too complex to program like tasks performed by humans/animals and tasks beyond human abilities. Some examples are listed below:
- <b>Recognizing patterns:</b> Speech Recognition, facial identity, etc
- <b>Recommender Systems:</b> Noisy data, commercial pay-off (e.g., Amazon, Netflix)
- <b>Information retrieval:</b> Find documents or images with similar content
- <b>Computer vision:</b> detection, segmentation, depth estimation, optical flow, etc.
- <b>Robotics:</b> perception, planning, autonomous driving etc
- Learning to play games

Specifically, the use learning algorithms are relevant in areas where:
1. Human expertise does not exist (e.g., bioinformatics)
2. Humans are unable to explain their expertise (speech recognition, computer vision)
3. Complex solutions change in time (routing computer networks)

### 1.2. What is Machine Learning?

Learning systems are not directly programmed to solve a problem, instead develop their own program based on:
- Examples of how they should behave
- From trial-and-error experience trying to solve the problem

Specifically, while a classical program is made of:
- Input: Data + Rules
- Output: Answers

a Machine learning program is made of:
- Input: Data + Answers
- Output: Rules

## 2. Taxonomy of of learning

In general Machine Learning algorithms differ by its input data and the following factors:

| Framework | Role | Teacher | Protocol |
|:------------:|:-------:|:-----------:|:--------------:|
| Supervised | Active | Helpful | Online |
| Unsupervised | Passive | Adversarial | Batch learning |

The most important factor is perhaps the framework. Here is a quick recap on the different cases.

### 2.1. Unsupervised learning

The main task of an unsupervised algorithm is to create a new representation $\tilde{X}$ of the data $X$. In practice, this representation is not a finality but rather a mean to another end. This is the case with PCA for instance, whose aim is to perform dimensionality reduction for:
- Reduce storage space and computational time
- Remove redundancies
- Weaken the curse of dimensionality
- Visualization (in 2 or 3 dimensions) and interpretability

Some other popular class of algorithms are data clustering algorithm.
- Understand general characteristics of the data
- Infer some properties of an object based on how it relates to other
objects
- Problems that can be solved by clustering?

### 2.2. Supervised learning

<b>Goal:</b> Make predictions: Data + Labels -> Model -> Predictor

- <i>Classification: Make discrete predictions
- <i>Regression: make real-valued predictions

<b>Definition: (Hypothesis class F:)</b> It is the space of possible decision functions we are considering. It answers the question "What shape do you think the discriminant should take?" and is chosen based on our beliefs about the problem.

<b>Definition: (Loss function)</b> Quantifies how far the decision function is from the truth?

<b>Goal:</b> we want a predictor $f$ with small loss on unseen data (e.g., on a test set).

### 3. Machine Learning Pipeline

Most Machine Learning problems are solved by the following pipeline:

1. Input data
2. Feature and model selection
3. Training model on training set (done via optimization)
4. Computing train + test output

And the <b>goals</b> are:
- Use “informative” features
- Pick a predictor that is
    * expressive
    * easy to train
    * doesn’t overfit
- Train a model to minimize training error

---

# 4. Optimization

## 4.1. Introduction

Most Machine Learning algorithms - if all - learn by minimizing some error.

A fundamental problem is that the true error is unavailable to the learner. Because the input of the algorithm is a sample $S$ and not the distribution $\mathcal{D}$ that generated the data.

This can have dramatic effects on the implementation of sound Machine Learning pipelines. The main one is overfitting, in which the learner becomes extremly good on the training set (<i>it kind of memorizes it</i>) but fails to generalizes to the remaining data.

## 4.2. Context and terminology

We will mainly focus on supervised learning, in which the error is the difference between our algorithm results and the expected results.

Let's recall that a learning algorihm receives as input a training set S sampled from an unknown distribution $\mathcal{D}$ and labeled by some target function $f$ (what we want to approximate).

---

## 5. Expected Risk Minimization

### 5.1. Basic definitions

<b>Definition: (Empirical error)</b> For a predictor $h \in \mathbb{H}$, the mean error the classifier over the training sample:

$$
L_{S}(h) := \frac{\mid \{ i \in [m]:h(x_{i}) \neq y_{i}\} \mid}{m} = \frac{\text{Number of errors among all samples}}{\text{Numbers of samples}}
$$

where $[m] = \{1, ..., m \}$.

<b>Expected Risk Minimization</b> Find a predictor $h$ that minimizes $L_{S}(h)$.

### 5.2. Overfitting

<b>Problem:</b> For a predictor $h \in \mathcal{H}$ we can over-learn on the training sample and it can lead to poor generalization.

A <b>common solution</b> is to apply the ERM learning rule over a restricted search space which we called a <i>hypothesis class</i>. Formally, it translates to this: among a set of predictor $\mathcal{H}$, solve:

$$
ERM_{\mathcal{H}}(S) \in argmin_{h\in \mathcal{H}} L_S(h)
$$

### 5.3. Inductive bias

<b>Definition: (Inductive bias)</b>  By restricting the learner to choosing a predictor from H, we bias it toward a particular set of predictors. It turns out that the incorporation of prior knowledge, biasing the learning process, is inevitable for the success of learning algorithms (this is formally stated and proved as the “No-Free-Lunch theorem” in Chapter 5).

Since the choice of such a restriction is determined before the learner sees the training data, it should ideally be based on some prior knowledge about the problem to be learned.

Roughly speaking, the stronger the prior knowledge (or prior assumptions) that one starts the learning process with, the easier it is to learn from further examples. However, the stronger these prior assumptions are, the less flexible the learning is – it is bound, a priori, by the commitment to these assumptions.

<b>Tradeoff of using a hypothesis class:</b>
- More restricted hypothesis class better protects us against overfitting
- At the same time might cause us a stronger inductive bias.

---

## 6. ERM with inductive bias

<b>Big question:</b> In learning theory, over which hypothesis classes ERM learning will not result in overfitting?

<b>Key takeaway:</b> By putting an upperobound on the size of H, we can show that the ERM will not overfit, provided it is based on a sufficiciently large training sample.

Let's apply $ERM_{\mathcal{H}}$ on our training sample S

$$
h_{S} \in \text{argmin}_{h\in \mathcal{H}}
$$

Prior to delving into the result, let's focus on the assumptions behind the

### 6.1. The realizability assumption

<b>Definition: (Realizability assumption)</b> There exists $h^{*} \in \mathcal{H}$ s.t. $L_{(\mathcal{D}, f)}(h^{*}) = 0$

It basically means that there exists a predictor that have loss 0 on the distribution (which imply that the loss on the training set is 0).

### 6.2. The i.i.d. assumption

<b>Definition: (i.i.d.)</b> The examples in the training set are independently and identically distributed (i.i.d.) according to the distribution $\mathcal{D}$

<b>Intuitively:</b> Training set $S$ is a window through which the learner gets partial information about the distribution D over the world and the labeling function, $f$. The larger the sample gets, the more likely it is to reflect more accurately the distribution and labeling used to generate it.

<b>Definitions:</b>
- $\sigma$ be the probability of getting a nonrepresentative sample
- $(1 - \sigma)$ the confidence parameter of our prediction.
- $\epsilon$ is the accuracy parameter

---

# 7. Probability of getting a wrong sample

<b>Goal:</b> Find an upper bounding the probability to sample m-tuple of in stances that will lead to failure of the learner.

<b>Theorem:</b>

$$
\mathbb{P}(\{ S_{x} \mid L_{(\mathcal{D}, f)}(h_{S}) > \epsilon \}) \mid \mathcal{H}\mid e^{-\epsilon m}
$$

<b>Corollary:</b> Let $\mathcal{H}$ be finite hypothesis class. Let $\delta \in (0, 1)$ and $\epsilon > 0$ and let $m$ be an integer that satisfies:

$$
m \geq \frac{log(\mid\mathcal{h}\mid)/\delta}{\epsilon}
$$

Then, for any labeling function f and for any distribution $\mathcal{D}$, for which the realizability assumption holds with probability at least $1-\delta$ over hte choice of an i.i.d. sample S of size m, we have that for every ERM hypothesis h_{S}, it holds that:

$$
L_{(D, f)}(h_{S}) \leq \epsilon
$$

---

## 8. Sources
- [Understanding Machine Learning: From Theory to Algorithms (Chapters 1 and 2)](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)
- [The Elements of Statistical Learning (Chapter 1)](https://web.stanford.edu/~hastie/ElemStatLearn)
- [Convex Optimization: Algorithms and Complexity (Sections 1.1, 1.2, 1.3)](http://sbubeck.com/Bubeck15.pdf)
- [Convex optimization and gradient descent, lecture notes by Nisheeth Vishnoi, EPFL (Sections 1.1, 1.2, 1.3)](http://theory.epfl.ch/vishnoi/Nisheeth-VishnoiFall2014-ConvexOptimization.pdf)

------
